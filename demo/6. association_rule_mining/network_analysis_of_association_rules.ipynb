{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Visualization of Association Rules\n",
    "\n",
    "\n",
    "In the context of Market Basket Analysis, Association Rules can be described as a set of relationships between the items\n",
    "that are purchased from the customers.\n",
    "* Apriori Algorithm:\n",
    "    * Support - The ratio of all transactions at which a specific item appears.\n",
    "\n",
    "    * Confidence - **Conf(A, B) = Support(A, B) / Support(A)**\n",
    "\n",
    "    * Lift - The probability of purchasing item B when item A is sold. **p(B; A) = Support(A, B) / (Support(A) * Support(B))**\n",
    "    \n",
    "Dataset - [E-commerce platform generated transactions](http://archive.ics.uci.edu/ml/machine-learning-databases/00352/Online%20Retail.xlsx)\n",
    "\n",
    "\n",
    "[Additional Information on Apriori](https://www.kaggle.com/code/parisanahmadi/how-to-solve-the-apriori-algorithm-in-a-simple-way)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please refer to requirements.txt for a full list of packages\n",
    "# pip install networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install efficient_apriori\n",
    "# !pip install networkx\n",
    "from efficient_apriori import apriori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "if os.path.exists('online_retail.csv'):\n",
    "    df = pd.read_csv('online_retail.csv')\n",
    "else:\n",
    "    df = pd.read_excel('http://archive.ics.uci.edu/ml/machine-learning-databases/00352/Online%20Retail.xlsx')\n",
    "\n",
    "    df.to_csv('online_retail.csv')\n",
    "\n",
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['InvoiceNo', 'Description']]\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= df.dropna(subset=['Description'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = df['Description'].value_counts().hist(bins=50, figsize = (15,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group sold items according their Invoice Number\n",
    "grouped_transac = df.groupby('InvoiceNo').agg(list)\n",
    "grouped_transac.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_transactions(items):\n",
    "    cleaned = list()\n",
    "    for item in items:\n",
    "        # print(item)\n",
    "        # Most of the values are string but there are some item numbers \n",
    "        cleaned.append(str(item).strip(' .'))\n",
    "    return tuple(cleaned)\n",
    "transactions = grouped_transac['Description'].apply(clean_transactions).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A shorthand way to implement the procedure above\n",
    "clean_transac = lambda t_list: tuple([x.strip(' .') for x in t_list])\n",
    "\n",
    "# transactions = grouped_transac['Description'].apply(clean_transac).tolist()\n",
    "transactions = grouped_transac['Description'].apply(clean_transactions).tolist()\n",
    "print(transactions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run apriori\n",
    "%time itemsets, rules = apriori(transactions, min_support=0.007, min_confidence=0.70, verbosity=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print top 10 rules with highest confidence\n",
    "for rule in sorted(rules, key=lambda rule: rule.confidence)[-10:]:\n",
    "  print(rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the Network/Graph\n",
    "network = nx.DiGraph()\n",
    "all_rules = []\n",
    "for n, rule in enumerate(rules[-100:]):\n",
    "    # Add rule node\n",
    "    rule_label = \"rule {}\".format(n)\n",
    "    all_rules.append(rule_label)\n",
    "    network.add_node(rule_label, lift=rule.lift)\n",
    "    \n",
    "    # Add nodes/items affecting the rule (lhs)\n",
    "    network.add_edges_from([(item, rule_label) for item in rule.lhs])\n",
    "    # Add nodes/items that are the outcome of the rule (rhs)\n",
    "    network.add_edges_from([(rule_label, item) for item in rule.rhs])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define matplotlib.pyplot axes(canvas)\n",
    "_, ax = plt.subplots(figsize=(17, 12))\n",
    "\n",
    "# nx.draw_spring(network, ax=ax)\n",
    "pos = nx.random_layout(network)\n",
    "\n",
    "# Draw edges\n",
    "edges = nx.draw_networkx_edges(network, pos, alpha=0.2, width=1.5)\n",
    "\n",
    "# Draw item nodes\n",
    "nx.draw_networkx_nodes(network, \n",
    "                       pos=pos, \n",
    "                       ax=ax,\n",
    "                       node_color='b',\n",
    "                       alpha=0.5,\n",
    "                       label='Items',\n",
    "                       nodelist=[node for node in network.nodes() if node not in all_rules])\n",
    "\n",
    "# Draw rule nodes\n",
    "nx.draw_networkx_nodes(network, \n",
    "                       pos=pos, \n",
    "                       ax=ax,\n",
    "                       node_color='g',\n",
    "                       alpha=0.7,\n",
    "                       node_shape='s',\n",
    "                       label='Rules',\n",
    "                       nodelist=[node for node in all_rules],\n",
    "                       node_size=[8*network.nodes[rule]['lift'] for rule in all_rules])\n",
    "\n",
    "# Draw node labels\n",
    "labels = nx.draw_networkx_labels(network,pos=pos, ax=ax, font_size=10)\n",
    "\n",
    "legend = ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Let's explore the data as network\n",
    "\n",
    "# Calculating network metrics first\n",
    "\n",
    "betweenness = nx.betweenness_centrality(network)\n",
    "# isinstance(bb, dict)\n",
    "# True\n",
    "nx.set_node_attributes(network, betweenness, \"betweenness\")\n",
    "\n",
    "# betweenness\n",
    "\n",
    "degree = dict(network.degree())\n",
    "nx.set_node_attributes(network, degree, \"degree\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.nodes(data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dataframe out of network nodes\n",
    "df = pd.DataFrame.from_dict(network.nodes(data=True))\n",
    "\n",
    "# pd.json_normalize(df[1])\n",
    "#pd.Series(df[1].tolist())\n",
    "\n",
    "df = pd.merge(df,pd.json_normalize(df[1]), left_index=True, right_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.scatterplot(data=df, x=\"degree\", y=\"betweenness\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Thank you')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: Try to improve the network visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
